# Large Language Model and Provenance Metadata for Determining Image and Video Relevance in News Stories

#### [Tomas Peterka]() and [Matyas Bohacek](https://www.matyasbohacek.com)

The most effective misinformation campaigns are multimodal. They often combine text with images and videos taken out of context to support the presented narrative—unless they are not fabricated altogether. Contemporary methods for detecting misinformation--be it in deepfakes or text articles--miss this interplay between multiple modalities. Built around a large language model, the system proposed in this paper overcomes such challenges. It analyzes the text of the article and the provenance metadata to determine if the attached media is relevant. We wrap the system in an intuitive web interface to demonstrate it at the conference and gather feedback.

> [See paper]() — See poster — [Contact us](mailto:maty-at-stanford-dot-edu)
> 
> _Pre-print released on arXiv_

## Getting Started

TBD

## Features

**C2PA Provenance Extraction.** TBD

**LLM Inference.** TBD

**Demo.** TBD

## Citation

```bibtex
TBD
```

## Remarks & Updates

- (**TBD Date**) The pre-print is released on arXiv.
